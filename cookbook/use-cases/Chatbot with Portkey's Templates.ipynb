{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1BZGkDisia_beCibB3eaep0n87cIcqShR?usp=sharing)\n"
      ],
      "metadata": {
        "id": "FDh1PjM8xXkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Portkey Prompt Templates to Build Your Chat Bot\n",
        "\n",
        "Portkey's prompt templates offer a powerful solution for testing and building chatbots.  You can easily input your model prompt, adjust settings like model type and temperature, and instantly view outputs. Portkey's robust versioning system ensures that you can experiment freely with your prompts without fear of breaking your production environment.  This seamless iteration process allows you to refine your chatbot's performance until you're satisfied.\n",
        "\n",
        "\n",
        "\n",
        "This notebook demonstrates how to build a chatbot using Portkey's Prompt Templates.\n",
        "\n",
        "[Link to docs](https://docs.portkey.ai/docs/guides/use-cases/build-a-chatbot-using-portkeys-prompt-templates) for detailed explanation."
      ],
      "metadata": {
        "id": "W1JF-7P1xDWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portkey_ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2N9puE3BwX6s",
        "outputId": "17877edd-8362-40d6-f6d4-e652150ddf5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portkey_ai\n",
            "  Downloading portkey_ai-1.8.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting httpx (from portkey_ai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting mypy<2.0,>=0.991 (from portkey_ai)\n",
            "  Downloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.7.1 in /usr/local/lib/python3.10/dist-packages (from portkey_ai) (4.12.2)\n",
            "Requirement already satisfied: pydantic>=1.10.12 in /usr/local/lib/python3.10/dist-packages (from portkey_ai) (2.8.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from portkey_ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from portkey_ai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from portkey_ai) (1.3.1)\n",
            "Collecting cached-property (from portkey_ai)\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from portkey_ai) (4.66.5)\n",
            "Collecting types-requests (from portkey_ai)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->portkey_ai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->portkey_ai) (1.2.2)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy<2.0,>=0.991->portkey_ai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy<2.0,>=0.991->portkey_ai) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.12->portkey_ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.12->portkey_ai) (2.20.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->portkey_ai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->portkey_ai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->portkey_ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.10/dist-packages (from types-requests->portkey_ai) (2.0.7)\n",
            "Downloading portkey_ai-1.8.5-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cached-property, types-requests, mypy-extensions, h11, mypy, httpcore, httpx, portkey_ai\n",
            "Successfully installed cached-property-1.5.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 mypy-1.11.2 mypy-extensions-1.0.0 portkey_ai-1.8.5 types-requests-2.32.0.20240712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Your Chatbot\n",
        "Go to [Portkey's Dashboard](https://app.portkey.ai).\n",
        "\n",
        "\n",
        "Click on Prompts and then the Create button.\n",
        "\n",
        "You are now on Prompt Playground.\n",
        "\n",
        "## Step 1: Define Your System Prompt\n",
        "Start by defining your system prompt. This sets the initial context and behavior for your chatbot. You can set this up in your Portkey's Prompt Library using the JSON View\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "[\n",
        "  {\n",
        "    \"content\": \"You're a helpful assistant.\",\n",
        "    \"role\": \"system\"\n",
        "  },\n",
        "  {{chat_history}} #This will be used in the next step\n",
        "]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Step 2: Create a Variable to Store Conversation History\n",
        "In the Portkey UI, Set the variable type: Look for two icons next to the variable name: \"T\" and \"{..}\". Click the \"{...}\" icon to switch to JSON mode.\n",
        "\n",
        "Initialize the variable with an empty array [ ]. This array will store the conversation history, allowing your chatbot to maintain context."
      ],
      "metadata": {
        "id": "e_1jTA-zxHYL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8axClGl8vGsA",
        "outputId": "67057b01-c29c-402f-bb4a-55d9a60073fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: I'm sorry, I'm not able to provide real-time weather updates. I recommend checking a weather website or app for the most up-to-date information on the weather in your area.\n",
            "You: fghfg'\n",
            "Bot: It looks like your message was incomplete or unclear. Is there something specific you would like assistance with? Feel free to ask any questions or provide more information.\n",
            "You: exit\n",
            "Conversation ended.\n"
          ]
        }
      ],
      "source": [
        "from portkey_ai import Portkey\n",
        "\n",
        "client = Portkey(\n",
        "    api_key=\"YOUR_PORTKEY_API_KEY\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def generate_response(conversation_history):\n",
        "    prompt_completion = client.prompts.completions.create(\n",
        "        prompt_id=\"YOUR_PROMPT_ID\",\n",
        "        variables={\n",
        "            \"variable\": conversation_history #Use the Varible name chosen by you\n",
        "        }\n",
        "    )\n",
        "    return prompt_completion.choices[0].message.content\n",
        "\n",
        "def append_response(conversation_history, response):\n",
        "    conversation_history.append({\n",
        "        \"content\": response,\n",
        "        \"role\": \"assistant\"\n",
        "    })\n",
        "    return conversation_history\n",
        "\n",
        "# Initial conversation\n",
        "conversation_history = [\n",
        "    {\n",
        "        \"content\": \"How can I help you today\",\n",
        "        \"role\": \"assistant\"\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"What is the weather like today?\",\n",
        "        \"role\": \"user\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Generate and append response\n",
        "response = generate_response(conversation_history)\n",
        "conversation_history = append_response(conversation_history, response)\n",
        "\n",
        "print(\"Bot:\", response)\n",
        "\n",
        "# Continue the conversation\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    conversation_history.append({\n",
        "        \"content\": user_input,\n",
        "        \"role\": \"user\"\n",
        "    })\n",
        "\n",
        "    response = generate_response(conversation_history)\n",
        "    conversation_history = append_response(conversation_history, response)\n",
        "\n",
        "    print(\"Bot:\", response)\n",
        "\n",
        "print(\"Conversation ended.\")"
      ]
    }
  ]
}